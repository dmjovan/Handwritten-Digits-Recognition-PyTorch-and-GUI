{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6165f7b5-b53c-4f10-90da-e7cf8e5a16cb",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd05d38f-3030-4f5a-a39e-fd1428871892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, colorchooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2000bb2f-5b9d-426f-86f9-ce037a3085e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0') \n",
    "    print('GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa5dbf-7bf1-48a9-a331-d1bc7cdcce6c",
   "metadata": {},
   "source": [
    "## Loading MNIST dataset for hand-drawn digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012c31e1-eb90-40c0-b77d-0b007be01ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jovan dmitrovic\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST('', train=True, download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "train_set = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9021f9-c6d9-4952-97a8-1744d1fc8549",
   "metadata": {},
   "source": [
    "## Creating Fully Conected Model as classifier for Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a603a471-e770-4eb1-935e-58d344f90ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConectedModel(nn.Module):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    # feed forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        output = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221873f-6142-467d-aefb-3512335c7943",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ced598-e9fc-4412-9b10-9c749fc6bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -------> Loss: 0.22930302\n",
      "Epoch 2 -------> Loss: 0.26051372\n",
      "Epoch 3 -------> Loss: 0.06764458\n",
      "Epoch 4 -------> Loss: 0.050637588\n",
      "Epoch 5 -------> Loss: 0.0095831165\n",
      "Epoch 6 -------> Loss: 0.142099\n",
      "Epoch 7 -------> Loss: 0.108616926\n",
      "Epoch 8 -------> Loss: 0.07913689\n",
      "Epoch 9 -------> Loss: 0.011538881\n",
      "Epoch 10 -------> Loss: 0.078684844\n",
      "Accuracy on test data: 0.974\n"
     ]
    }
   ],
   "source": [
    "model = FullyConectedModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# training model on training dataset\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_set: \n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        model.zero_grad()  \n",
    "        output = model(X.view(-1,28*28)) \n",
    "        loss = F.nll_loss(output, y) # nll stands for negative log-likelihood\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    print('Epoch ' + str(epoch+1) + ' -------> Loss: ' + str(loss.cpu().detach().numpy()))  \n",
    "    \n",
    "# evaluation of model on testing dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_set:\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = model(X.view(-1,28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('Accuracy on test data: ' + str(round(correct/total, 3)))\n",
    "torch.save(model, 'models/mnist_fc.pt')\n",
    "# model = torch.load('models/mnist_fc.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f038c6e-dd21-4ba7-aabb-6ed7cf34a0ac",
   "metadata": {},
   "source": [
    "## Creating Convolutional Model (VGG like) as classifier for Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d4f02c-98bc-4092-bd02-603e85e6d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModel(nn.Module):\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(1024, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    # feed forward function\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        output = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return output\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8fde8a-d4c0-4883-963a-36e13f327213",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4dbc51f-2cf2-461c-b3ad-3c770c233f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -------> Loss: 0.009229989\n",
      "Epoch 2 -------> Loss: 0.12891479\n",
      "Epoch 3 -------> Loss: 0.011686894\n",
      "Epoch 4 -------> Loss: 0.074636534\n",
      "Epoch 5 -------> Loss: 0.020816639\n",
      "Epoch 6 -------> Loss: 0.01277717\n",
      "Epoch 7 -------> Loss: 0.005591956\n",
      "Epoch 8 -------> Loss: 0.018048646\n",
      "Epoch 9 -------> Loss: 0.010655026\n",
      "Epoch 10 -------> Loss: 0.00015884734\n",
      "Epoch 11 -------> Loss: 0.0019440919\n",
      "Epoch 12 -------> Loss: 0.0003182065\n",
      "Epoch 13 -------> Loss: 1.69082e-05\n",
      "Epoch 14 -------> Loss: 0.00022395699\n",
      "Epoch 15 -------> Loss: 2.2910338e-06\n",
      "Accuracy on test data: 0.991\n"
     ]
    }
   ],
   "source": [
    "model = ConvModel().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "# training model on training dataset\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_set: \n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        model.zero_grad()  \n",
    "        output = model(X.view(-1,1,28,28)) \n",
    "        loss = F.nll_loss(output, y) # nll stands for negative log-likelihood\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    print('Epoch ' + str(epoch+1) + ' -------> Loss: ' + str(loss.cpu().detach().numpy()))  \n",
    "    \n",
    "# evaluation of model on testing dataset\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_set:\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        output = model(X.view(-1,1,28,28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print('Accuracy on test data: ' + str(round(correct/total, 3)))\n",
    "torch.save(model, 'models/mnist_cnn.pt')\n",
    "# model = torch.load('models/mnist_cnn.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
